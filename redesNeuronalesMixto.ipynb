{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal mixta conjunta con datos numéricos e imágenes\n",
    "Para esta parte final, se parte de los datasets ya separados en train y test. Contienen los datos numéricos además se usa la ruta de la imagen en el mismo orden que los datasets numéricos de train y test.\n",
    "\n",
    "Estos datasets se obtuvieron en el notebook dedicado al tratamiento de datos. [Tratamiento de datos](limpiezaCategEscalado.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Carga el dataset y devuelve un dataframe de Pandas\n",
    "def load_airbnb_dataset(ruta,nombre):\n",
    "    csv_path = os.path.join(ruta, nombre)\n",
    "    return pd.read_csv(csv_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_airbnb_dataset('datasets','trainFinal.csv')\n",
    "test = load_airbnb_dataset('datasets','testFinal.csv')\n",
    "dfTrainImagenes = load_airbnb_dataset('datasets','imagenesTrainFinal.csv')\n",
    "dfTestImagenes = load_airbnb_dataset('datasets','imagenesTestFinal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def cargaImagenes(dataF):\n",
    "    inputImages = []\n",
    "\n",
    "    origHeight = 144\n",
    "    origWidth = 216\n",
    "    origChann = 3\n",
    "\n",
    "    for ruta in dataF['imagenLocal']:\n",
    "        image = cv2.imread(ruta)\n",
    "\n",
    "        height, width, channels = image.shape\n",
    "\n",
    "        if (height != origHeight) or (width != origWidth) or (channels != origChann):\n",
    "            raise ValueError('Tamaño incorrecto en imagen:', ruta)\n",
    "        \n",
    "        inputImages.append(image)\n",
    "\n",
    "    return np.array(inputImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenesTrain = cargaImagenes(dfTrainImagenes)\n",
    "imagenesTest = cargaImagenes(dfTestImagenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalado de datos\n",
    "### Escalar imágenes en rango de 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenesTrain = imagenesTrain / 2550.\n",
    "imagenesTest = imagenesTest / 2550."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalar datos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Separar la Y del resto\n",
    "dataPrecio = train['Price']\n",
    "dataSinPrecio = train.drop(['Price'], axis=1, inplace=False)\n",
    "\n",
    "dataPrecioTest = test['Price']\n",
    "dataSinPrecioTest = test.drop(['Price'], axis=1, inplace=False)\n",
    "\n",
    "y_train = dataPrecio.values\n",
    "X_train = dataSinPrecio.values\n",
    "\n",
    "y_test = dataPrecioTest.values\n",
    "X_test = dataSinPrecioTest.values\n",
    "\n",
    "feature_names = train.columns[:]\n",
    "\n",
    "# Obtener precio máximo en Train, y escalamos los precios de test y train en rango de [0, 1]\n",
    "maxPrice = train[\"Price\"].max()\n",
    "trainY = train[\"Price\"] / maxPrice\n",
    "testY = test[\"Price\"] / maxPrice\n",
    "\n",
    "# Se escala las variables numéricas de train y test\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "XtestScaled = scaler.transform(X_test)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "XtrainScaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def create_mlp(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=dim, activation=\"relu\"))    \n",
    "    model.add(BatchNormalization())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal Convolucional (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # if this is the first CONV layer then set the input\n",
    "        # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "\n",
    "        # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(10)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    # return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de modelos / Concatenación MLP con CNN / Obtención del modelo final\n",
    "Obtenemos ahora el modelo MLP y el CNN, luego se concatena y generamos un nuevo modelo con la unión final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programas\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "# create the MLP and CNN models\n",
    "mlp = create_mlp(XtrainScaled.shape[1])\n",
    "cnn = create_cnn(216, 144, 3, regress=False)\n",
    "\n",
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilamos y entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========] - 33s 4ms/step - loss: 28.0543 - val_loss: 28.1741\n",
      "Epoch 16/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 28.3897 - val_loss: 29.0487\n",
      "Epoch 17/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.7149 - val_loss: 29.0508\n",
      "Epoch 18/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.9503 - val_loss: 28.5798\n",
      "Epoch 19/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.7729 - val_loss: 28.6547\n",
      "Epoch 20/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.7174 - val_loss: 29.0551\n",
      "Epoch 21/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.5310 - val_loss: 28.0410\n",
      "Epoch 22/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.2779 - val_loss: 28.6544\n",
      "Epoch 23/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.2309 - val_loss: 28.4718\n",
      "Epoch 24/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.4571 - val_loss: 28.0661\n",
      "Epoch 25/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.2870 - val_loss: 30.1919\n",
      "Epoch 26/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.4937 - val_loss: 28.7926\n",
      "Epoch 27/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.3187 - val_loss: 28.8146\n",
      "Epoch 28/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.2446 - val_loss: 28.4041\n",
      "Epoch 29/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.0371 - val_loss: 28.1530\n",
      "Epoch 30/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.1164 - val_loss: 27.9328\n",
      "Epoch 31/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.1405 - val_loss: 27.9397\n",
      "Epoch 32/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.7695 - val_loss: 27.6832\n",
      "Epoch 33/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.1271 - val_loss: 29.3432\n",
      "Epoch 34/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.0250 - val_loss: 27.7892\n",
      "Epoch 35/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.6713 - val_loss: 28.1670\n",
      "Epoch 36/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.8907 - val_loss: 28.4717\n",
      "Epoch 37/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.5219 - val_loss: 28.2170\n",
      "Epoch 38/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.9026 - val_loss: 27.6807\n",
      "Epoch 39/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 27.0962 - val_loss: 28.4416\n",
      "Epoch 40/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.0823 - val_loss: 27.6967\n",
      "Epoch 41/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.6009 - val_loss: 27.6590\n",
      "Epoch 42/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.5219 - val_loss: 28.2397\n",
      "Epoch 43/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.2371 - val_loss: 27.1721\n",
      "Epoch 44/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.4859 - val_loss: 27.5642\n",
      "Epoch 45/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.5442 - val_loss: 27.9303\n",
      "Epoch 46/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.3705 - val_loss: 28.2053\n",
      "Epoch 47/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.2807 - val_loss: 28.6734\n",
      "Epoch 48/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.1188 - val_loss: 27.8429\n",
      "Epoch 49/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.1137 - val_loss: 27.9014\n",
      "Epoch 50/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.2736 - val_loss: 27.4764\n",
      "Epoch 51/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 26.3545 - val_loss: 28.2365\n",
      "Epoch 52/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.9504 - val_loss: 27.3349\n",
      "Epoch 53/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.5268 - val_loss: 27.7059\n",
      "Epoch 54/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.5315 - val_loss: 27.6794\n",
      "Epoch 55/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.9157 - val_loss: 28.3490\n",
      "Epoch 56/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.7160 - val_loss: 28.3812\n",
      "Epoch 57/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.8960 - val_loss: 28.0838\n",
      "Epoch 58/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.9260 - val_loss: 27.4495\n",
      "Epoch 59/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.6261 - val_loss: 28.7424\n",
      "Epoch 60/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.3391 - val_loss: 28.1162\n",
      "Epoch 61/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.2542 - val_loss: 28.8317\n",
      "Epoch 62/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.6853 - val_loss: 27.6062\n",
      "Epoch 63/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.2746 - val_loss: 29.0081\n",
      "Epoch 64/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.4955 - val_loss: 28.6129\n",
      "Epoch 65/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.9581 - val_loss: 27.5871\n",
      "Epoch 66/200\n",
      "8262/8262 [==============================] - 33s 4ms/step - loss: 25.5824 - val_loss: 28.0747\n",
      "Epoch 67/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 25.3179 - val_loss: 28.5645\n",
      "Epoch 68/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.9396 - val_loss: 28.3400\n",
      "Epoch 69/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.9069 - val_loss: 28.7617\n",
      "Epoch 70/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.7198 - val_loss: 28.3012\n",
      "Epoch 71/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.7497 - val_loss: 29.1124\n",
      "Epoch 72/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.1757 - val_loss: 28.3772\n",
      "Epoch 73/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.0827 - val_loss: 28.1445\n",
      "Epoch 74/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.3664 - val_loss: 29.4638\n",
      "Epoch 75/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.6314 - val_loss: 28.8008\n",
      "Epoch 76/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.5313 - val_loss: 28.6743\n",
      "Epoch 77/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.0749 - val_loss: 28.0282\n",
      "Epoch 78/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.0219 - val_loss: 28.2207\n",
      "Epoch 79/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.1542 - val_loss: 28.4774\n",
      "Epoch 80/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.9505 - val_loss: 28.5340\n",
      "Epoch 81/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.1021 - val_loss: 28.6677\n",
      "Epoch 82/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.8153 - val_loss: 28.9306\n",
      "Epoch 83/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.8569 - val_loss: 28.0866\n",
      "Epoch 84/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.8779 - val_loss: 29.7601\n",
      "Epoch 85/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 24.0548 - val_loss: 28.6280\n",
      "Epoch 86/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.5849 - val_loss: 28.1485\n",
      "Epoch 87/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.4412 - val_loss: 29.0951\n",
      "Epoch 88/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.7873 - val_loss: 29.1730\n",
      "Epoch 89/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.7750 - val_loss: 28.8772\n",
      "Epoch 90/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.3500 - val_loss: 28.4319\n",
      "Epoch 91/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.2534 - val_loss: 29.1842\n",
      "Epoch 92/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.0750 - val_loss: 28.8034\n",
      "Epoch 93/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.6336 - val_loss: 28.6542\n",
      "Epoch 94/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.9711 - val_loss: 29.3459\n",
      "Epoch 95/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 23.0399 - val_loss: 29.0081\n",
      "Epoch 96/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.6320 - val_loss: 28.5299\n",
      "Epoch 97/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.7603 - val_loss: 29.4240\n",
      "Epoch 98/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.6161 - val_loss: 29.2891\n",
      "Epoch 99/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.6100 - val_loss: 28.6045\n",
      "Epoch 100/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.4533 - val_loss: 28.8577\n",
      "Epoch 101/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.7360 - val_loss: 28.4744\n",
      "Epoch 102/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.4587 - val_loss: 29.4620\n",
      "Epoch 103/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.3013 - val_loss: 29.1156\n",
      "Epoch 104/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.3567 - val_loss: 28.5219\n",
      "Epoch 105/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.8023 - val_loss: 28.7323\n",
      "Epoch 106/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.9015 - val_loss: 28.5500\n",
      "Epoch 107/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.7370 - val_loss: 28.4748\n",
      "Epoch 108/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.2692 - val_loss: 28.7472\n",
      "Epoch 109/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.4039 - val_loss: 29.1514\n",
      "Epoch 110/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 22.2910 - val_loss: 29.0972\n",
      "Epoch 111/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.7917 - val_loss: 28.8204\n",
      "Epoch 112/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.8119 - val_loss: 28.7792\n",
      "Epoch 113/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.9846 - val_loss: 29.3696\n",
      "Epoch 114/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.6779 - val_loss: 28.9749\n",
      "Epoch 115/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.7342 - val_loss: 29.4081\n",
      "Epoch 116/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.4408 - val_loss: 28.9700\n",
      "Epoch 117/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.8448 - val_loss: 29.7182\n",
      "Epoch 118/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.2608 - val_loss: 29.3371\n",
      "Epoch 119/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.5147 - val_loss: 29.6739\n",
      "Epoch 120/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.6816 - val_loss: 29.4463\n",
      "Epoch 121/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.1382 - val_loss: 29.2513\n",
      "Epoch 122/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.4174 - val_loss: 28.9831\n",
      "Epoch 123/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.3209 - val_loss: 29.1978\n",
      "Epoch 124/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.9263 - val_loss: 30.1228\n",
      "Epoch 125/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.5811 - val_loss: 29.2352\n",
      "Epoch 126/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.3586 - val_loss: 29.3220\n",
      "Epoch 127/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.2132 - val_loss: 29.1359\n",
      "Epoch 128/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 21.3903 - val_loss: 29.2845\n",
      "Epoch 129/200\n",
      "8262/8262 [==============================] - 32s 4ms/step - loss: 20.7972 - val_loss: 29.5960\n",
      "Epoch 130/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.9651 - val_loss: 29.8643\n",
      "Epoch 131/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 21.3868 - val_loss: 30.0479\n",
      "Epoch 132/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 21.1417 - val_loss: 29.3552\n",
      "Epoch 133/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.8082 - val_loss: 29.5364\n",
      "Epoch 134/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.9912 - val_loss: 29.8797\n",
      "Epoch 135/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 21.6092 - val_loss: 29.9556\n",
      "Epoch 136/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.4179 - val_loss: 29.8141\n",
      "Epoch 137/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.5132 - val_loss: 30.0086\n",
      "Epoch 138/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.7757 - val_loss: 29.7826\n",
      "Epoch 139/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.9607 - val_loss: 30.1162\n",
      "Epoch 140/200\n",
      "8262/8262 [==============================] - 31s 4ms/step - loss: 20.8851 - val_loss: 29.6566\n",
      "Epoch 141/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.6286 - val_loss: 30.3707\n",
      "Epoch 142/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.8487 - val_loss: 30.0798\n",
      "Epoch 143/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.8292 - val_loss: 29.8604\n",
      "Epoch 144/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.8211 - val_loss: 29.8207\n",
      "Epoch 145/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.0177 - val_loss: 30.3693\n",
      "Epoch 146/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.4255 - val_loss: 30.0639\n",
      "Epoch 147/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.8212 - val_loss: 29.7123\n",
      "Epoch 148/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.5359 - val_loss: 29.6526\n",
      "Epoch 149/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.5351 - val_loss: 30.2106\n",
      "Epoch 150/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.0346 - val_loss: 30.2251\n",
      "Epoch 151/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.0686 - val_loss: 30.2071\n",
      "Epoch 152/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.7972 - val_loss: 30.3016\n",
      "Epoch 153/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.1896 - val_loss: 30.7341\n",
      "Epoch 154/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.0142 - val_loss: 31.1941\n",
      "Epoch 155/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.7887 - val_loss: 30.3557\n",
      "Epoch 156/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.1396 - val_loss: 30.4685\n",
      "Epoch 157/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.8482 - val_loss: 29.8848\n",
      "Epoch 158/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.4648 - val_loss: 29.7180\n",
      "Epoch 159/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.0718 - val_loss: 30.7773\n",
      "Epoch 160/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.7620 - val_loss: 29.8175\n",
      "Epoch 161/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.1118 - val_loss: 30.6506\n",
      "Epoch 162/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.9696 - val_loss: 30.8712\n",
      "Epoch 163/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.2173 - val_loss: 30.4277\n",
      "Epoch 164/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 20.0413 - val_loss: 30.6768\n",
      "Epoch 165/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.8521 - val_loss: 30.8422\n",
      "Epoch 166/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.8495 - val_loss: 30.7722\n",
      "Epoch 167/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.8178 - val_loss: 30.9476\n",
      "Epoch 168/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.9793 - val_loss: 30.6629\n",
      "Epoch 169/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.4922 - val_loss: 31.0291\n",
      "Epoch 170/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.7590 - val_loss: 30.9253\n",
      "Epoch 171/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.8154 - val_loss: 31.8376\n",
      "Epoch 172/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.3832 - val_loss: 30.3462\n",
      "Epoch 173/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.6372 - val_loss: 30.7997\n",
      "Epoch 174/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.3899 - val_loss: 31.2026\n",
      "Epoch 175/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.8823 - val_loss: 31.0809\n",
      "Epoch 176/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.6914 - val_loss: 31.1641\n",
      "Epoch 177/200\n",
      "8262/8262 [==============================] - 31s 4ms/step - loss: 19.3443 - val_loss: 31.2282\n",
      "Epoch 178/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.5400 - val_loss: 31.0756\n",
      "Epoch 179/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.5730 - val_loss: 30.6778\n",
      "Epoch 180/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.2429 - val_loss: 30.9433\n",
      "Epoch 181/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.1564 - val_loss: 30.9689\n",
      "Epoch 182/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.6534 - val_loss: 31.2988\n",
      "Epoch 183/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.0738 - val_loss: 31.2971\n",
      "Epoch 184/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.1740 - val_loss: 30.8568\n",
      "Epoch 185/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.5054 - val_loss: 31.4428\n",
      "Epoch 186/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.0627 - val_loss: 31.1450\n",
      "Epoch 187/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.0146 - val_loss: 31.6012\n",
      "Epoch 188/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.1552 - val_loss: 31.2217\n",
      "Epoch 189/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.3385 - val_loss: 30.6657\n",
      "Epoch 190/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.3520 - val_loss: 31.0236\n",
      "Epoch 191/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.2531 - val_loss: 31.2228\n",
      "Epoch 192/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.1398 - val_loss: 30.9593\n",
      "Epoch 193/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 19.3441 - val_loss: 30.6940\n",
      "Epoch 194/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 18.6835 - val_loss: 31.2343\n",
      "Epoch 195/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 18.9408 - val_loss: 31.1724\n",
      "Epoch 196/200\n",
      "8262/8262 [==============================] - 31s 4ms/step - loss: 18.7567 - val_loss: 31.0828\n",
      "Epoch 197/200\n",
      "8262/8262 [==============================] - 31s 4ms/step - loss: 18.5519 - val_loss: 31.1522\n",
      "Epoch 198/200\n",
      "8262/8262 [==============================] - 31s 4ms/step - loss: 18.9277 - val_loss: 30.9905\n",
      "Epoch 199/200\n",
      "8262/8262 [==============================] - 30s 4ms/step - loss: 18.9468 - val_loss: 31.7414\n",
      "Epoch 200/200\n",
      "8262/8262 [==============================] - 31s 4ms/step - loss: 19.2246 - val_loss: 30.0529\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "historico = model.fit(\n",
    "\t[XtrainScaled, imagenesTrain], trainY,\n",
    "\tvalidation_data=([XtestScaled, imagenesTest], testY),\n",
    "\tepochs=200, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa overfitting y se obtiene un error del 19% en train y del 30% en test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de pérdidas (plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 388.965625 277.314375\" width=\"388.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">\r\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\r\n",
       "  </style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M -0 277.314375 \r\n",
       "L 388.965625 277.314375 \r\n",
       "L 388.965625 0 \r\n",
       "L -0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 46.965625 239.758125 \r\n",
       "L 381.765625 239.758125 \r\n",
       "L 381.765625 22.318125 \r\n",
       "L 46.965625 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m301345d0e5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.183807\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(59.002557 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"100.420445\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 25 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "       <path d=\"M 10.796875 72.90625 \r\n",
       "L 49.515625 72.90625 \r\n",
       "L 49.515625 64.59375 \r\n",
       "L 19.828125 64.59375 \r\n",
       "L 19.828125 46.734375 \r\n",
       "Q 21.96875 47.46875 24.109375 47.828125 \r\n",
       "Q 26.265625 48.1875 28.421875 48.1875 \r\n",
       "Q 40.625 48.1875 47.75 41.5 \r\n",
       "Q 54.890625 34.8125 54.890625 23.390625 \r\n",
       "Q 54.890625 11.625 47.5625 5.09375 \r\n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \r\n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \r\n",
       "Q 12.796875 0.140625 7.71875 1.703125 \r\n",
       "L 7.71875 11.625 \r\n",
       "Q 12.109375 9.234375 16.796875 8.0625 \r\n",
       "Q 21.484375 6.890625 26.703125 6.890625 \r\n",
       "Q 35.15625 6.890625 40.078125 11.328125 \r\n",
       "Q 45.015625 15.765625 45.015625 23.390625 \r\n",
       "Q 45.015625 31 40.078125 35.4375 \r\n",
       "Q 35.15625 39.890625 26.703125 39.890625 \r\n",
       "Q 22.75 39.890625 18.8125 39.015625 \r\n",
       "Q 14.890625 38.140625 10.796875 36.28125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-53\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(94.057945 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.657082\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 50 -->\r\n",
       "      <g transform=\"translate(132.294582 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"176.89372\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 75 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 8.203125 72.90625 \r\n",
       "L 55.078125 72.90625 \r\n",
       "L 55.078125 68.703125 \r\n",
       "L 28.609375 0 \r\n",
       "L 18.3125 0 \r\n",
       "L 43.21875 64.59375 \r\n",
       "L 8.203125 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-55\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(170.53122 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-55\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"215.130358\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 100 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(205.586608 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_6\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"253.366995\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 125 -->\r\n",
       "      <g transform=\"translate(243.823245 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_7\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"291.603633\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 150 -->\r\n",
       "      <g transform=\"translate(282.059883 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_8\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"329.840271\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 175 -->\r\n",
       "      <g transform=\"translate(320.296521 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_9\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.076909\" xlink:href=\"#m301345d0e5\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 200 -->\r\n",
       "      <g transform=\"translate(358.533159 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_10\">\r\n",
       "     <!-- Epoch # -->\r\n",
       "     <defs>\r\n",
       "      <path d=\"M 9.8125 72.90625 \r\n",
       "L 55.90625 72.90625 \r\n",
       "L 55.90625 64.59375 \r\n",
       "L 19.671875 64.59375 \r\n",
       "L 19.671875 43.015625 \r\n",
       "L 54.390625 43.015625 \r\n",
       "L 54.390625 34.71875 \r\n",
       "L 19.671875 34.71875 \r\n",
       "L 19.671875 8.296875 \r\n",
       "L 56.78125 8.296875 \r\n",
       "L 56.78125 0 \r\n",
       "L 9.8125 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-69\"/>\r\n",
       "      <path d=\"M 18.109375 8.203125 \r\n",
       "L 18.109375 -20.796875 \r\n",
       "L 9.078125 -20.796875 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.390625 \r\n",
       "Q 20.953125 51.265625 25.265625 53.625 \r\n",
       "Q 29.59375 56 35.59375 56 \r\n",
       "Q 45.5625 56 51.78125 48.09375 \r\n",
       "Q 58.015625 40.1875 58.015625 27.296875 \r\n",
       "Q 58.015625 14.40625 51.78125 6.484375 \r\n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \r\n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \r\n",
       "Q 20.953125 3.328125 18.109375 8.203125 \r\n",
       "z\r\n",
       "M 48.6875 27.296875 \r\n",
       "Q 48.6875 37.203125 44.609375 42.84375 \r\n",
       "Q 40.53125 48.484375 33.40625 48.484375 \r\n",
       "Q 26.265625 48.484375 22.1875 42.84375 \r\n",
       "Q 18.109375 37.203125 18.109375 27.296875 \r\n",
       "Q 18.109375 17.390625 22.1875 11.75 \r\n",
       "Q 26.265625 6.109375 33.40625 6.109375 \r\n",
       "Q 40.53125 6.109375 44.609375 11.75 \r\n",
       "Q 48.6875 17.390625 48.6875 27.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-112\"/>\r\n",
       "      <path d=\"M 30.609375 48.390625 \r\n",
       "Q 23.390625 48.390625 19.1875 42.75 \r\n",
       "Q 14.984375 37.109375 14.984375 27.296875 \r\n",
       "Q 14.984375 17.484375 19.15625 11.84375 \r\n",
       "Q 23.34375 6.203125 30.609375 6.203125 \r\n",
       "Q 37.796875 6.203125 41.984375 11.859375 \r\n",
       "Q 46.1875 17.53125 46.1875 27.296875 \r\n",
       "Q 46.1875 37.015625 41.984375 42.703125 \r\n",
       "Q 37.796875 48.390625 30.609375 48.390625 \r\n",
       "z\r\n",
       "M 30.609375 56 \r\n",
       "Q 42.328125 56 49.015625 48.375 \r\n",
       "Q 55.71875 40.765625 55.71875 27.296875 \r\n",
       "Q 55.71875 13.875 49.015625 6.21875 \r\n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \r\n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \r\n",
       "Q 5.515625 13.875 5.515625 27.296875 \r\n",
       "Q 5.515625 40.765625 12.171875 48.375 \r\n",
       "Q 18.84375 56 30.609375 56 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-111\"/>\r\n",
       "      <path d=\"M 48.78125 52.59375 \r\n",
       "L 48.78125 44.1875 \r\n",
       "Q 44.96875 46.296875 41.140625 47.34375 \r\n",
       "Q 37.3125 48.390625 33.40625 48.390625 \r\n",
       "Q 24.65625 48.390625 19.8125 42.84375 \r\n",
       "Q 14.984375 37.3125 14.984375 27.296875 \r\n",
       "Q 14.984375 17.28125 19.8125 11.734375 \r\n",
       "Q 24.65625 6.203125 33.40625 6.203125 \r\n",
       "Q 37.3125 6.203125 41.140625 7.25 \r\n",
       "Q 44.96875 8.296875 48.78125 10.40625 \r\n",
       "L 48.78125 2.09375 \r\n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \r\n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \r\n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \r\n",
       "Q 5.515625 14.109375 5.515625 27.296875 \r\n",
       "Q 5.515625 40.671875 12.859375 48.328125 \r\n",
       "Q 20.21875 56 33.015625 56 \r\n",
       "Q 37.15625 56 41.109375 55.140625 \r\n",
       "Q 45.0625 54.296875 48.78125 52.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-99\"/>\r\n",
       "      <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 75.984375 \r\n",
       "L 18.109375 75.984375 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-104\"/>\r\n",
       "      <path id=\"DejaVuSans-32\"/>\r\n",
       "      <path d=\"M 51.125 44 \r\n",
       "L 36.921875 44 \r\n",
       "L 32.8125 27.6875 \r\n",
       "L 47.125 27.6875 \r\n",
       "z\r\n",
       "M 43.796875 71.78125 \r\n",
       "L 38.71875 51.515625 \r\n",
       "L 52.984375 51.515625 \r\n",
       "L 58.109375 71.78125 \r\n",
       "L 65.921875 71.78125 \r\n",
       "L 60.890625 51.515625 \r\n",
       "L 76.125 51.515625 \r\n",
       "L 76.125 44 \r\n",
       "L 58.984375 44 \r\n",
       "L 54.984375 27.6875 \r\n",
       "L 70.515625 27.6875 \r\n",
       "L 70.515625 20.21875 \r\n",
       "L 53.078125 20.21875 \r\n",
       "L 48 0 \r\n",
       "L 40.1875 0 \r\n",
       "L 45.21875 20.21875 \r\n",
       "L 30.90625 20.21875 \r\n",
       "L 25.875 0 \r\n",
       "L 18.015625 0 \r\n",
       "L 23.09375 20.21875 \r\n",
       "L 7.71875 20.21875 \r\n",
       "L 7.71875 27.6875 \r\n",
       "L 24.90625 27.6875 \r\n",
       "L 29 44 \r\n",
       "L 13.28125 44 \r\n",
       "L 13.28125 51.515625 \r\n",
       "L 30.90625 51.515625 \r\n",
       "L 35.890625 71.78125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\"/>\r\n",
       "     </defs>\r\n",
       "     <g transform=\"translate(193.275781 268.034687)scale(0.1 -0.1)\">\r\n",
       "      <use xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n",
       "      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n",
       "      <use x=\"306.201172\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"337.988281\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m2e16ce2d89\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"226.35361\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(27.240625 230.152829)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"202.040242\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- 30 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 40.578125 39.3125 \r\n",
       "Q 47.65625 37.796875 51.625 33 \r\n",
       "Q 55.609375 28.21875 55.609375 21.1875 \r\n",
       "Q 55.609375 10.40625 48.1875 4.484375 \r\n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \r\n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \r\n",
       "Q 12.796875 0.390625 7.625 2.203125 \r\n",
       "L 7.625 11.71875 \r\n",
       "Q 11.71875 9.328125 16.59375 8.109375 \r\n",
       "Q 21.484375 6.890625 26.8125 6.890625 \r\n",
       "Q 36.078125 6.890625 40.9375 10.546875 \r\n",
       "Q 45.796875 14.203125 45.796875 21.1875 \r\n",
       "Q 45.796875 27.640625 41.28125 31.265625 \r\n",
       "Q 36.765625 34.90625 28.71875 34.90625 \r\n",
       "L 20.21875 34.90625 \r\n",
       "L 20.21875 43.015625 \r\n",
       "L 29.109375 43.015625 \r\n",
       "Q 36.375 43.015625 40.234375 45.921875 \r\n",
       "Q 44.09375 48.828125 44.09375 54.296875 \r\n",
       "Q 44.09375 59.90625 40.109375 62.90625 \r\n",
       "Q 36.140625 65.921875 28.71875 65.921875 \r\n",
       "Q 24.65625 65.921875 20.015625 65.03125 \r\n",
       "Q 15.375 64.15625 9.8125 62.3125 \r\n",
       "L 9.8125 71.09375 \r\n",
       "Q 15.4375 72.65625 20.34375 73.4375 \r\n",
       "Q 25.25 74.21875 29.59375 74.21875 \r\n",
       "Q 40.828125 74.21875 47.359375 69.109375 \r\n",
       "Q 53.90625 64.015625 53.90625 55.328125 \r\n",
       "Q 53.90625 49.265625 50.4375 45.09375 \r\n",
       "Q 46.96875 40.921875 40.578125 39.3125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-51\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(27.240625 205.83946)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"177.726873\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_13\">\r\n",
       "      <!-- 40 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(27.240625 181.526092)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_13\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"153.413505\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_14\">\r\n",
       "      <!-- 50 -->\r\n",
       "      <g transform=\"translate(27.240625 157.212724)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_14\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"129.100137\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_15\">\r\n",
       "      <!-- 60 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 33.015625 40.375 \r\n",
       "Q 26.375 40.375 22.484375 35.828125 \r\n",
       "Q 18.609375 31.296875 18.609375 23.390625 \r\n",
       "Q 18.609375 15.53125 22.484375 10.953125 \r\n",
       "Q 26.375 6.390625 33.015625 6.390625 \r\n",
       "Q 39.65625 6.390625 43.53125 10.953125 \r\n",
       "Q 47.40625 15.53125 47.40625 23.390625 \r\n",
       "Q 47.40625 31.296875 43.53125 35.828125 \r\n",
       "Q 39.65625 40.375 33.015625 40.375 \r\n",
       "z\r\n",
       "M 52.59375 71.296875 \r\n",
       "L 52.59375 62.3125 \r\n",
       "Q 48.875 64.0625 45.09375 64.984375 \r\n",
       "Q 41.3125 65.921875 37.59375 65.921875 \r\n",
       "Q 27.828125 65.921875 22.671875 59.328125 \r\n",
       "Q 17.53125 52.734375 16.796875 39.40625 \r\n",
       "Q 19.671875 43.65625 24.015625 45.921875 \r\n",
       "Q 28.375 48.1875 33.59375 48.1875 \r\n",
       "Q 44.578125 48.1875 50.953125 41.515625 \r\n",
       "Q 57.328125 34.859375 57.328125 23.390625 \r\n",
       "Q 57.328125 12.15625 50.6875 5.359375 \r\n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \r\n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \r\n",
       "Q 6.984375 17.96875 6.984375 36.375 \r\n",
       "Q 6.984375 53.65625 15.1875 63.9375 \r\n",
       "Q 23.390625 74.21875 37.203125 74.21875 \r\n",
       "Q 40.921875 74.21875 44.703125 73.484375 \r\n",
       "Q 48.484375 72.75 52.59375 71.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-54\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(27.240625 132.899356)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_15\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"104.786768\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_16\">\r\n",
       "      <!-- 70 -->\r\n",
       "      <g transform=\"translate(27.240625 108.585987)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-55\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_7\">\r\n",
       "     <g id=\"line2d_16\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"80.4734\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_17\">\r\n",
       "      <!-- 80 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 31.78125 34.625 \r\n",
       "Q 24.75 34.625 20.71875 30.859375 \r\n",
       "Q 16.703125 27.09375 16.703125 20.515625 \r\n",
       "Q 16.703125 13.921875 20.71875 10.15625 \r\n",
       "Q 24.75 6.390625 31.78125 6.390625 \r\n",
       "Q 38.8125 6.390625 42.859375 10.171875 \r\n",
       "Q 46.921875 13.96875 46.921875 20.515625 \r\n",
       "Q 46.921875 27.09375 42.890625 30.859375 \r\n",
       "Q 38.875 34.625 31.78125 34.625 \r\n",
       "z\r\n",
       "M 21.921875 38.8125 \r\n",
       "Q 15.578125 40.375 12.03125 44.71875 \r\n",
       "Q 8.5 49.078125 8.5 55.328125 \r\n",
       "Q 8.5 64.0625 14.71875 69.140625 \r\n",
       "Q 20.953125 74.21875 31.78125 74.21875 \r\n",
       "Q 42.671875 74.21875 48.875 69.140625 \r\n",
       "Q 55.078125 64.0625 55.078125 55.328125 \r\n",
       "Q 55.078125 49.078125 51.53125 44.71875 \r\n",
       "Q 48 40.375 41.703125 38.8125 \r\n",
       "Q 48.828125 37.15625 52.796875 32.3125 \r\n",
       "Q 56.78125 27.484375 56.78125 20.515625 \r\n",
       "Q 56.78125 9.90625 50.3125 4.234375 \r\n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.734375 -1.421875 13.25 4.234375 \r\n",
       "Q 6.78125 9.90625 6.78125 20.515625 \r\n",
       "Q 6.78125 27.484375 10.78125 32.3125 \r\n",
       "Q 14.796875 37.15625 21.921875 38.8125 \r\n",
       "z\r\n",
       "M 18.3125 54.390625 \r\n",
       "Q 18.3125 48.734375 21.84375 45.5625 \r\n",
       "Q 25.390625 42.390625 31.78125 42.390625 \r\n",
       "Q 38.140625 42.390625 41.71875 45.5625 \r\n",
       "Q 45.3125 48.734375 45.3125 54.390625 \r\n",
       "Q 45.3125 60.0625 41.71875 63.234375 \r\n",
       "Q 38.140625 66.40625 31.78125 66.40625 \r\n",
       "Q 25.390625 66.40625 21.84375 63.234375 \r\n",
       "Q 18.3125 60.0625 18.3125 54.390625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-56\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(27.240625 84.272619)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_8\">\r\n",
       "     <g id=\"line2d_17\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"56.160032\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_18\">\r\n",
       "      <!-- 90 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 10.984375 1.515625 \r\n",
       "L 10.984375 10.5 \r\n",
       "Q 14.703125 8.734375 18.5 7.8125 \r\n",
       "Q 22.3125 6.890625 25.984375 6.890625 \r\n",
       "Q 35.75 6.890625 40.890625 13.453125 \r\n",
       "Q 46.046875 20.015625 46.78125 33.40625 \r\n",
       "Q 43.953125 29.203125 39.59375 26.953125 \r\n",
       "Q 35.25 24.703125 29.984375 24.703125 \r\n",
       "Q 19.046875 24.703125 12.671875 31.3125 \r\n",
       "Q 6.296875 37.9375 6.296875 49.421875 \r\n",
       "Q 6.296875 60.640625 12.9375 67.421875 \r\n",
       "Q 19.578125 74.21875 30.609375 74.21875 \r\n",
       "Q 43.265625 74.21875 49.921875 64.515625 \r\n",
       "Q 56.59375 54.828125 56.59375 36.375 \r\n",
       "Q 56.59375 19.140625 48.40625 8.859375 \r\n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \r\n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \r\n",
       "Q 15.09375 0.046875 10.984375 1.515625 \r\n",
       "z\r\n",
       "M 30.609375 32.421875 \r\n",
       "Q 37.25 32.421875 41.125 36.953125 \r\n",
       "Q 45.015625 41.5 45.015625 49.421875 \r\n",
       "Q 45.015625 57.28125 41.125 61.84375 \r\n",
       "Q 37.25 66.40625 30.609375 66.40625 \r\n",
       "Q 23.96875 66.40625 20.09375 61.84375 \r\n",
       "Q 16.21875 57.28125 16.21875 49.421875 \r\n",
       "Q 16.21875 41.5 20.09375 36.953125 \r\n",
       "Q 23.96875 32.421875 30.609375 32.421875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-57\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(27.240625 59.959251)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-57\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_9\">\r\n",
       "     <g id=\"line2d_18\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m2e16ce2d89\" y=\"31.846664\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_19\">\r\n",
       "      <!-- 100 -->\r\n",
       "      <g transform=\"translate(20.878125 35.645882)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_20\">\r\n",
       "     <!-- Loss -->\r\n",
       "     <defs>\r\n",
       "      <path d=\"M 9.8125 72.90625 \r\n",
       "L 19.671875 72.90625 \r\n",
       "L 19.671875 8.296875 \r\n",
       "L 55.171875 8.296875 \r\n",
       "L 55.171875 0 \r\n",
       "L 9.8125 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-76\"/>\r\n",
       "      <path d=\"M 44.28125 53.078125 \r\n",
       "L 44.28125 44.578125 \r\n",
       "Q 40.484375 46.53125 36.375 47.5 \r\n",
       "Q 32.28125 48.484375 27.875 48.484375 \r\n",
       "Q 21.1875 48.484375 17.84375 46.4375 \r\n",
       "Q 14.5 44.390625 14.5 40.28125 \r\n",
       "Q 14.5 37.15625 16.890625 35.375 \r\n",
       "Q 19.28125 33.59375 26.515625 31.984375 \r\n",
       "L 29.59375 31.296875 \r\n",
       "Q 39.15625 29.25 43.1875 25.515625 \r\n",
       "Q 47.21875 21.78125 47.21875 15.09375 \r\n",
       "Q 47.21875 7.46875 41.1875 3.015625 \r\n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \r\n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \r\n",
       "Q 10.6875 0.296875 5.421875 2 \r\n",
       "L 5.421875 11.28125 \r\n",
       "Q 10.40625 8.6875 15.234375 7.390625 \r\n",
       "Q 20.0625 6.109375 24.8125 6.109375 \r\n",
       "Q 31.15625 6.109375 34.5625 8.28125 \r\n",
       "Q 37.984375 10.453125 37.984375 14.40625 \r\n",
       "Q 37.984375 18.0625 35.515625 20.015625 \r\n",
       "Q 33.0625 21.96875 24.703125 23.78125 \r\n",
       "L 21.578125 24.515625 \r\n",
       "Q 13.234375 26.265625 9.515625 29.90625 \r\n",
       "Q 5.8125 33.546875 5.8125 39.890625 \r\n",
       "Q 5.8125 47.609375 11.28125 51.796875 \r\n",
       "Q 16.75 56 26.8125 56 \r\n",
       "Q 31.78125 56 36.171875 55.265625 \r\n",
       "Q 40.578125 54.546875 44.28125 53.078125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-115\"/>\r\n",
       "     </defs>\r\n",
       "     <g transform=\"translate(14.798438 142.092031)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\r\n",
       "      <use x=\"55.697266\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"116.878906\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"168.978516\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_19\">\r\n",
       "    <path clip-path=\"url(#p00f2fd650d)\" d=\"M 62.183807 32.201761 \r\n",
       "L 63.713272 161.039398 \r\n",
       "L 65.242738 173.787541 \r\n",
       "L 66.772203 190.64951 \r\n",
       "L 68.301669 196.879563 \r\n",
       "L 69.831134 200.705188 \r\n",
       "L 71.3606 202.19716 \r\n",
       "L 72.890065 204.929679 \r\n",
       "L 74.419531 204.015253 \r\n",
       "L 75.948996 204.075237 \r\n",
       "L 77.478462 204.726557 \r\n",
       "L 79.007927 206.298212 \r\n",
       "L 80.537393 206.396861 \r\n",
       "L 82.066858 206.950063 \r\n",
       "L 83.596324 206.770942 \r\n",
       "L 85.125789 205.95549 \r\n",
       "L 86.655255 207.596157 \r\n",
       "L 88.18472 207.02384 \r\n",
       "L 89.714186 207.454985 \r\n",
       "L 91.243651 207.589927 \r\n",
       "L 92.773117 208.043204 \r\n",
       "L 94.302583 208.658579 \r\n",
       "L 95.832048 208.772897 \r\n",
       "L 97.361514 208.222853 \r\n",
       "L 98.890979 208.636423 \r\n",
       "L 100.420445 208.133976 \r\n",
       "L 101.94991 208.559365 \r\n",
       "L 103.479376 208.739573 \r\n",
       "L 105.008841 209.244125 \r\n",
       "L 106.538307 209.051278 \r\n",
       "L 108.067772 208.992599 \r\n",
       "L 109.597238 209.894704 \r\n",
       "L 111.126703 209.025235 \r\n",
       "L 112.656169 209.273422 \r\n",
       "L 114.185634 210.133347 \r\n",
       "L 115.7151 209.599887 \r\n",
       "L 117.244565 210.496583 \r\n",
       "L 118.774031 209.571103 \r\n",
       "L 120.303496 209.100399 \r\n",
       "L 121.832962 211.565594 \r\n",
       "L 123.362427 210.304561 \r\n",
       "L 124.891893 210.496609 \r\n",
       "L 126.421358 211.189195 \r\n",
       "L 127.950824 210.584313 \r\n",
       "L 129.480289 210.442382 \r\n",
       "L 131.009755 210.864855 \r\n",
       "L 132.53922 211.083013 \r\n",
       "L 134.068686 211.476814 \r\n",
       "L 135.598151 211.489265 \r\n",
       "L 137.127617 211.100421 \r\n",
       "L 138.657082 210.903574 \r\n",
       "L 141.716013 212.916054 \r\n",
       "L 143.245479 212.904717 \r\n",
       "L 144.774944 211.970576 \r\n",
       "L 146.30441 212.456073 \r\n",
       "L 147.833875 212.018553 \r\n",
       "L 149.363341 211.94555 \r\n",
       "L 152.422272 213.372515 \r\n",
       "L 153.951737 213.578884 \r\n",
       "L 155.481203 212.530758 \r\n",
       "L 157.010668 213.529281 \r\n",
       "L 158.540134 212.99217 \r\n",
       "L 160.069599 214.298711 \r\n",
       "L 161.599065 212.780804 \r\n",
       "L 163.12853 213.42404 \r\n",
       "L 164.657996 214.343726 \r\n",
       "L 166.187461 214.423181 \r\n",
       "L 167.716927 214.878125 \r\n",
       "L 169.246392 214.805491 \r\n",
       "L 170.775858 216.201159 \r\n",
       "L 172.305323 216.427096 \r\n",
       "L 175.364255 215.093029 \r\n",
       "L 176.89372 215.336427 \r\n",
       "L 178.423186 216.44619 \r\n",
       "L 179.952651 216.574915 \r\n",
       "L 181.482117 216.253439 \r\n",
       "L 183.011582 216.748605 \r\n",
       "L 184.541048 216.379973 \r\n",
       "L 186.070513 217.077289 \r\n",
       "L 189.129444 216.92523 \r\n",
       "L 190.65891 216.495138 \r\n",
       "L 192.188375 217.637485 \r\n",
       "L 193.717841 217.986845 \r\n",
       "L 195.247306 217.145386 \r\n",
       "L 196.776772 217.175373 \r\n",
       "L 198.306237 218.208736 \r\n",
       "L 199.835703 218.443532 \r\n",
       "L 201.365168 218.877347 \r\n",
       "L 202.894634 219.950357 \r\n",
       "L 204.424099 219.12998 \r\n",
       "L 205.953565 218.962498 \r\n",
       "L 207.48303 219.954405 \r\n",
       "L 209.012496 219.64249 \r\n",
       "L 210.541961 219.993067 \r\n",
       "L 212.071427 220.007896 \r\n",
       "L 213.600892 220.388795 \r\n",
       "L 215.130358 219.701561 \r\n",
       "L 216.659823 220.375761 \r\n",
       "L 218.189289 220.758261 \r\n",
       "L 219.718754 220.623745 \r\n",
       "L 221.24822 219.540177 \r\n",
       "L 222.777685 219.299081 \r\n",
       "L 224.307151 219.699111 \r\n",
       "L 225.836616 220.836524 \r\n",
       "L 227.366082 220.508891 \r\n",
       "L 228.895547 220.783304 \r\n",
       "L 230.425013 221.997452 \r\n",
       "L 231.954478 221.948179 \r\n",
       "L 233.483944 221.528421 \r\n",
       "L 235.013409 222.2741 \r\n",
       "L 236.542875 222.137278 \r\n",
       "L 238.07234 222.850533 \r\n",
       "L 239.601806 221.868234 \r\n",
       "L 241.131271 223.288059 \r\n",
       "L 242.660737 222.67086 \r\n",
       "L 244.190202 222.26507 \r\n",
       "L 245.719668 223.58617 \r\n",
       "L 247.249133 222.907407 \r\n",
       "L 248.778599 223.142166 \r\n",
       "L 250.308064 221.670019 \r\n",
       "L 251.83753 222.509461 \r\n",
       "L 253.366995 223.050496 \r\n",
       "L 254.896461 223.403878 \r\n",
       "L 256.425927 222.973433 \r\n",
       "L 257.955392 224.415364 \r\n",
       "L 259.484858 224.007054 \r\n",
       "L 261.014323 222.981916 \r\n",
       "L 262.543789 223.577789 \r\n",
       "L 264.073254 224.388525 \r\n",
       "L 265.60272 223.943734 \r\n",
       "L 267.132185 222.441132 \r\n",
       "L 268.661651 225.337524 \r\n",
       "L 270.191116 225.105777 \r\n",
       "L 271.720582 224.467552 \r\n",
       "L 273.250047 224.017798 \r\n",
       "L 274.779513 224.201636 \r\n",
       "L 276.308978 224.82516 \r\n",
       "L 277.838444 224.29014 \r\n",
       "L 280.897375 224.357291 \r\n",
       "L 282.42684 226.31066 \r\n",
       "L 285.485771 224.357045 \r\n",
       "L 287.015237 225.050565 \r\n",
       "L 288.544702 225.052541 \r\n",
       "L 290.074168 226.26953 \r\n",
       "L 291.603633 226.186928 \r\n",
       "L 293.133099 226.846695 \r\n",
       "L 294.662564 225.89266 \r\n",
       "L 296.19203 226.31905 \r\n",
       "L 297.721495 226.867305 \r\n",
       "L 299.250961 226.014156 \r\n",
       "L 300.780426 226.722748 \r\n",
       "L 302.309892 225.223571 \r\n",
       "L 303.839357 226.179057 \r\n",
       "L 305.368823 226.932337 \r\n",
       "L 306.898288 226.081766 \r\n",
       "L 308.427754 226.427507 \r\n",
       "L 309.957219 225.825174 \r\n",
       "L 313.01615 226.713222 \r\n",
       "L 316.075081 226.7965 \r\n",
       "L 317.604547 226.403898 \r\n",
       "L 319.134012 227.588167 \r\n",
       "L 320.663478 226.939659 \r\n",
       "L 322.192943 226.80251 \r\n",
       "L 323.722409 227.853268 \r\n",
       "L 325.251874 227.23577 \r\n",
       "L 326.78134 227.836958 \r\n",
       "L 328.310805 226.639893 \r\n",
       "L 329.840271 227.104 \r\n",
       "L 331.369736 227.947946 \r\n",
       "L 332.899202 227.471929 \r\n",
       "L 334.428667 227.391782 \r\n",
       "L 335.958133 228.194284 \r\n",
       "L 337.487599 228.404572 \r\n",
       "L 339.017064 227.196199 \r\n",
       "L 340.54653 228.605421 \r\n",
       "L 342.075995 228.362003 \r\n",
       "L 343.605461 227.556245 \r\n",
       "L 345.134926 228.632564 \r\n",
       "L 346.664392 228.749422 \r\n",
       "L 349.723323 227.961885 \r\n",
       "L 351.252788 227.929107 \r\n",
       "L 354.311719 228.444945 \r\n",
       "L 355.841185 227.948397 \r\n",
       "L 357.37065 229.554542 \r\n",
       "L 358.900116 228.92899 \r\n",
       "L 361.959047 229.874489 \r\n",
       "L 363.488512 228.96066 \r\n",
       "L 365.017978 228.914295 \r\n",
       "L 366.547443 228.238934 \r\n",
       "L 366.547443 228.238934 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 46.965625 239.758125 \r\n",
       "L 46.965625 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 381.765625 239.758125 \r\n",
       "L 381.765625 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 46.965625 239.758125 \r\n",
       "L 381.765625 239.758125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 46.965625 22.318125 \r\n",
       "L 381.765625 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_21\">\r\n",
       "    <!-- Training Loss -->\r\n",
       "    <defs>\r\n",
       "     <path d=\"M -0.296875 72.90625 \r\n",
       "L 61.375 72.90625 \r\n",
       "L 61.375 64.59375 \r\n",
       "L 35.5 64.59375 \r\n",
       "L 35.5 0 \r\n",
       "L 25.59375 0 \r\n",
       "L 25.59375 64.59375 \r\n",
       "L -0.296875 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-84\"/>\r\n",
       "     <path d=\"M 41.109375 46.296875 \r\n",
       "Q 39.59375 47.171875 37.8125 47.578125 \r\n",
       "Q 36.03125 48 33.890625 48 \r\n",
       "Q 26.265625 48 22.1875 43.046875 \r\n",
       "Q 18.109375 38.09375 18.109375 28.8125 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 20.953125 51.171875 25.484375 53.578125 \r\n",
       "Q 30.03125 56 36.53125 56 \r\n",
       "Q 37.453125 56 38.578125 55.875 \r\n",
       "Q 39.703125 55.765625 41.0625 55.515625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-114\"/>\r\n",
       "     <path d=\"M 34.28125 27.484375 \r\n",
       "Q 23.390625 27.484375 19.1875 25 \r\n",
       "Q 14.984375 22.515625 14.984375 16.5 \r\n",
       "Q 14.984375 11.71875 18.140625 8.90625 \r\n",
       "Q 21.296875 6.109375 26.703125 6.109375 \r\n",
       "Q 34.1875 6.109375 38.703125 11.40625 \r\n",
       "Q 43.21875 16.703125 43.21875 25.484375 \r\n",
       "L 43.21875 27.484375 \r\n",
       "z\r\n",
       "M 52.203125 31.203125 \r\n",
       "L 52.203125 0 \r\n",
       "L 43.21875 0 \r\n",
       "L 43.21875 8.296875 \r\n",
       "Q 40.140625 3.328125 35.546875 0.953125 \r\n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \r\n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \r\n",
       "Q 6 8.015625 6 15.921875 \r\n",
       "Q 6 25.140625 12.171875 29.828125 \r\n",
       "Q 18.359375 34.515625 30.609375 34.515625 \r\n",
       "L 43.21875 34.515625 \r\n",
       "L 43.21875 35.40625 \r\n",
       "Q 43.21875 41.609375 39.140625 45 \r\n",
       "Q 35.0625 48.390625 27.6875 48.390625 \r\n",
       "Q 23 48.390625 18.546875 47.265625 \r\n",
       "Q 14.109375 46.140625 10.015625 43.890625 \r\n",
       "L 10.015625 52.203125 \r\n",
       "Q 14.9375 54.109375 19.578125 55.046875 \r\n",
       "Q 24.21875 56 28.609375 56 \r\n",
       "Q 40.484375 56 46.34375 49.84375 \r\n",
       "Q 52.203125 43.703125 52.203125 31.203125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-97\"/>\r\n",
       "     <path d=\"M 9.421875 54.6875 \r\n",
       "L 18.40625 54.6875 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 64.59375 \r\n",
       "L 9.421875 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-105\"/>\r\n",
       "     <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-110\"/>\r\n",
       "     <path d=\"M 45.40625 27.984375 \r\n",
       "Q 45.40625 37.75 41.375 43.109375 \r\n",
       "Q 37.359375 48.484375 30.078125 48.484375 \r\n",
       "Q 22.859375 48.484375 18.828125 43.109375 \r\n",
       "Q 14.796875 37.75 14.796875 27.984375 \r\n",
       "Q 14.796875 18.265625 18.828125 12.890625 \r\n",
       "Q 22.859375 7.515625 30.078125 7.515625 \r\n",
       "Q 37.359375 7.515625 41.375 12.890625 \r\n",
       "Q 45.40625 18.265625 45.40625 27.984375 \r\n",
       "z\r\n",
       "M 54.390625 6.78125 \r\n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \r\n",
       "Q 42 -20.796875 29.203125 -20.796875 \r\n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \r\n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \r\n",
       "L 12.109375 -9.1875 \r\n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \r\n",
       "Q 23.78125 -13.375 27.78125 -13.375 \r\n",
       "Q 36.625 -13.375 41.015625 -8.765625 \r\n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \r\n",
       "L 45.40625 9.625 \r\n",
       "Q 42.625 4.78125 38.28125 2.390625 \r\n",
       "Q 33.9375 0 27.875 0 \r\n",
       "Q 17.828125 0 11.671875 7.65625 \r\n",
       "Q 5.515625 15.328125 5.515625 27.984375 \r\n",
       "Q 5.515625 40.671875 11.671875 48.328125 \r\n",
       "Q 17.828125 56 27.875 56 \r\n",
       "Q 33.9375 56 38.28125 53.609375 \r\n",
       "Q 42.625 51.21875 45.40625 46.390625 \r\n",
       "L 45.40625 54.6875 \r\n",
       "L 54.390625 54.6875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-103\"/>\r\n",
       "    </defs>\r\n",
       "    <g transform=\"translate(174.65125 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-84\"/>\r\n",
       "     <use x=\"60.865234\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "     <use x=\"101.978516\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "     <use x=\"163.257812\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "     <use x=\"191.041016\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "     <use x=\"254.419922\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "     <use x=\"282.203125\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "     <use x=\"345.582031\" xlink:href=\"#DejaVuSans-103\"/>\r\n",
       "     <use x=\"409.058594\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "     <use x=\"440.845703\" xlink:href=\"#DejaVuSans-76\"/>\r\n",
       "     <use x=\"496.542969\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "     <use x=\"557.724609\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "     <use x=\"609.824219\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p00f2fd650d\">\r\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"46.965625\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(0, 200), historico.history[\"loss\"])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo mixto final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] predicting house prices...\n",
      "[INFO] media precio apartamento: 68,24 €, desviación precio apartamento: 68,01 €\n",
      "[INFO] media: 30.05%, desviación: 25.79%\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "\n",
    "print(\"[INFO] predicting house prices...\")\n",
    "preds = model.predict([XtestScaled, imagenesTest])\n",
    "\n",
    "# Cargar dataset original\n",
    "df = load_airbnb_dataset('datasets', 'datasetImagenesFinal.csv')\n",
    "\n",
    "# compute the difference between the *predicted* house prices and the\n",
    "# *actual* house prices, then compute the percentage difference and\n",
    "# the absolute percentage difference\n",
    "diff = preds.flatten() - testY\n",
    "percentDiff = (diff / testY) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "\n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    "\n",
    "# finally, show some statistics on our model\n",
    "locale.setlocale(locale.LC_ALL, \"es_ES.UTF-8\")\n",
    "print(\"[INFO] media precio apartamento: {}, desviación precio apartamento: {}\".format(\n",
    "\tlocale.currency(df[\"Price\"].mean(), grouping=True),\n",
    "\tlocale.currency(df[\"Price\"].std(), grouping=True)))\n",
    "print(\"[INFO] media: {:.2f}%, desviación: {:.2f}%\".format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "La red mixta resulta tener una pérdida del 19,22% en train y un 30,05% en test.\n",
    "\n",
    "El cálculo de error absoluto es del 30,05% y una desviación del 25,79%."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
